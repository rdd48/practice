{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "labels = []\n",
    "\n",
    "with open('input/bbc_text_cls.csv') as f:\n",
    "    running_art = ''\n",
    "    for l in f.readlines()[1:]:\n",
    "        if '\",' not in l or '\", ' in l:\n",
    "            running_art += f'{l.strip()} '\n",
    "        else:\n",
    "            last_line = l.split('\",')\n",
    "            assert len(last_line) == 2\n",
    "            articles.append(running_art + last_line[0].strip())\n",
    "            labels.append(last_line[1].strip())\n",
    "            running_art = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>/?@#^&*_~'''\n",
    "\n",
    "def remove_punc(s):\n",
    "    ''' takes in a string, removes all \"useless\" punctuation, lowercases it '''\n",
    "    no_punc = ''\n",
    "    for char in s:\n",
    "        if char not in punc:\n",
    "            no_punc += char.lower()\n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def articles_to_mm(articles):\n",
    "    # mm structure will be mm[(word_idx-1, word_idx+1)] = [list of words that fit this pattern]\n",
    "    # for start of line, will use an initial state distribution with structure isd\n",
    "    isd = {}\n",
    "    mm = {}\n",
    "\n",
    "    for article in articles:\n",
    "        words = remove_punc(article).split()\n",
    "        assert len(words) > 0\n",
    "\n",
    "        \n",
    "        for idx, w in enumerate(words):\n",
    "\n",
    "            # first word in line for generating the isd\n",
    "            if idx == 0:\n",
    "                next_w = words[idx+1]\n",
    "                if next_w not in isd:\n",
    "                    isd[next_w] = []\n",
    "                isd[next_w].append(w)\n",
    "            \n",
    "            # generate mm for all words before the end\n",
    "            # but add an END token if it's the end of a sentence\n",
    "            elif idx < len(words) - 1:\n",
    "                prev_w = words[idx-1] # if '.' not in w else 'START'\n",
    "                next_w = words[idx+1] # if '.' not in w else 'END'\n",
    "\n",
    "                if (prev_w, next_w) not in mm:\n",
    "                    mm[(prev_w, next_w)] = []\n",
    "                mm[(prev_w, next_w)].append(w)\n",
    "            \n",
    "            elif idx == len(words) -1:\n",
    "                prev_w = words[idx-1]\n",
    "                next_w = 'END'\n",
    "                if (prev_w, next_w) not in mm:\n",
    "                    mm[(prev_w, next_w)] = []\n",
    "                mm[(prev_w, next_w)].append(w)\n",
    "    \n",
    "    return isd, mm\n",
    "\n",
    "isd, mm = articles_to_mm(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dict(d):\n",
    "    ''' convert list of words in isd to dict of word probs '''\n",
    "    d_norm = {}\n",
    "    for k,v in d.items():\n",
    "        # case where there's only one word to choose from\n",
    "        if len(v) == 1:\n",
    "            d_norm[k] = {v[0]: 1.}\n",
    "        \n",
    "        # multiple words\n",
    "        elif len(v) > 1:\n",
    "            count_dict = {}\n",
    "            for w in v:\n",
    "                count_dict[w] = v.count(w)\n",
    "            \n",
    "            prob_dict = {}\n",
    "            cum_sum = sum(count_dict.values())\n",
    "            for count_k,count_v in count_dict.items():\n",
    "                prob_dict[count_k] = count_v / cum_sum\n",
    "            \n",
    "            d_norm[k] = prob_dict\n",
    "        \n",
    "    return d_norm\n",
    "\n",
    "isd_norm = normalize_dict(isd)\n",
    "mm_norm = normalize_dict(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_from_dist(d):\n",
    "    # d is a dict with form {key: prob, k2: p2 ... }\n",
    "    return np.random.choice(list(d.keys()), p=list(d.values()))\n",
    "\n",
    "def get_random_article(articles):\n",
    "    return remove_punc(np.random.choice(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collins coming in england lineup england have named bath prop matt dawson. Is the starting xv for the six nations clash with hewitt. At lansdowne road on sunday. Fellow bath prop duncan bell will depend of the report as coach andy robinson makes just one has to their reports that bangor seized by 3% it would be the first time after two years and a win against the all of last year. Leicester centre ollie smith and andy could have been drafted onto the bench. Stevens takes place from phil vickery who want a robotic arm playing for the last year. Im confident he will make this week to for his appeal against ireland said nearly all the parties have shown outstanding pieces of the most people told southeast roost a miracle over italy. Gavi vehicle records the club added our selection beckons when players demonstrate such consistent ability. This game against jonah will be respectful. We reckon its a pc game for themselves. This season. England showed that sale sharks prop andrew sheridan was even played for britain because of the injury he came up for fight cost of his agenda during last fridays match against leeds. J robinson sale sharks capt m cueto sale sharks j noon newcastle o barkley bath j worsley wasps c hodgson sale sharks h ellis leicester g murphy leicester s thompson northampton m stevens bath d bell bath b kay leicester j lewsey wasps l moody leicester m corry leicester. A titterrell sale sharks d grewcock bath s borthwick bath a hazell gloucester m dawson played a goode leicester o smith leicester.\n"
     ]
    }
   ],
   "source": [
    "my_article = get_random_article(articles).split()\n",
    "new_article = []\n",
    "for idx, word in enumerate(my_article):\n",
    "    if idx == 0:\n",
    "        next_word = my_article[idx+1]\n",
    "        new_word = pick_from_dist(isd_norm[next_word])\n",
    "    \n",
    "    elif idx < len(my_article) - 1:\n",
    "        prev_word = my_article[idx-1]\n",
    "        next_word = my_article[idx+1]\n",
    "        new_word = pick_from_dist(mm_norm[(prev_word, next_word)])\n",
    "    \n",
    "    elif idx == len(my_article) - 1:\n",
    "        prev_word = my_article[idx-1]\n",
    "        next_word = 'END'\n",
    "        new_word = f'{pick_from_dist(mm_norm[(prev_word, next_word)])}. '\n",
    "    \n",
    "    new_article.append(new_word)\n",
    "\n",
    "# the -2 removes the trailing period\n",
    "new_article_str = ' '.join(new_article)[:-2]\n",
    "\n",
    "# capitalize first letter\n",
    "test = [x.capitalize() for x in new_article_str.split('. ')]\n",
    "final_art = '. '.join(test)\n",
    "print(final_art)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb92fd372a38b58e9d9a6055cb8e345cfb54abe6393cd0e132548b13249ccdef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
