{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "def remove_punc(l):\n",
    "    split_l = l.split()\n",
    "    new_l = []\n",
    "    for word in split_l:\n",
    "        no_punc = ''\n",
    "        for char in word:\n",
    "            if char not in punc:\n",
    "                no_punc += char\n",
    "        new_l.append(no_punc.lower())\n",
    "    return new_l\n",
    "\n",
    "def poem_to_list(txt_file):\n",
    "    '''train test split + split lines from input'''\n",
    "    saved_lines = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            # check that line has data\n",
    "            if len(l.strip()) > 0:\n",
    "                # split and remove punctuation\n",
    "                split_l = remove_punc(l)\n",
    "                saved_lines.append(split_l)\n",
    "    return saved_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "poe_lines = poem_to_list('input/edgar_allan_poe.txt')\n",
    "frost_lines = poem_to_list('input/robert_frost.txt')\n",
    "\n",
    "poe_labels = ['poe' for line in poe_lines]\n",
    "frost_labels = ['frost' for line in frost_lines]\n",
    "\n",
    "X = poe_lines + frost_lines\n",
    "y = poe_labels + frost_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'which', 'it', 'doth', 'now', 'know'] poe\n"
     ]
    }
   ],
   "source": [
    "print(X_train[509], y_train[509])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_mapping(train, test):\n",
    "    word2int = {}\n",
    "    word_freq = {}\n",
    "    idx = 0\n",
    "\n",
    "    # create unique int index for each word in train\n",
    "    for line in train:\n",
    "        for word in line:\n",
    "            if word not in word2int:\n",
    "                word2int[word] = idx\n",
    "                word_freq[word] = 1\n",
    "                idx += 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    \n",
    "    # use same index for all words in train not in test\n",
    "    idx += 1\n",
    "    for line in test:\n",
    "        for word in line:\n",
    "            if word not in word2int:\n",
    "                word2int[word] = idx\n",
    "                word_freq[word] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "\n",
    "    return word2int, word_freq\n",
    "\n",
    "word2int, word_freq = build_word_mapping(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_ints(X_data):\n",
    "    new_X = []\n",
    "    for line in X_data:\n",
    "        int_line = [word2int[word] for word in line]\n",
    "        new_X.append(int_line)\n",
    "    \n",
    "    return new_X\n",
    "\n",
    "X_train_int = words_to_ints(X_train)\n",
    "X_test_int = words_to_ints(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_markov_model(X_train_data):\n",
    "\n",
    "    # initialize state transition matrix\n",
    "    # size = num of unique words in train + extra token for non-train words\n",
    "    A_shape = max(word2int.values()) + 1\n",
    "    A = np.ones((A_shape, A_shape))\n",
    "\n",
    "    # initialize initial state distribution, vector of len A_shape\n",
    "    pi = np.ones((A_shape, 1))\n",
    "\n",
    "    # loop through all words and add to both transition matrix & initial dist.\n",
    "    for line in X_train_data:\n",
    "        for idx in range(len(line) - 1):\n",
    "            curr_word = line[idx]\n",
    "            next_word = line[idx + 1]\n",
    "            A[curr_word, next_word] += 1\n",
    "\n",
    "            if idx == 0:\n",
    "                pi[curr_word] += 1\n",
    "\n",
    "    # get probabilities for initial state by dividing counts by total num seqs\n",
    "    # Denom needs N (num sequences in dataset, aka len(X_train)??) + M (possible words aka A_shape)\n",
    "    pi /= (len(X_train_data) + A_shape)\n",
    "\n",
    "    # divide each count by total appearances of first word\n",
    "    # (in the transition matrix)\n",
    "    # the -2 weirdness in the loop accounts for the \"token\" word, i.e. a bucket for words only in the test set\n",
    "    int2word = {v: k for k, v in word2int.items()}\n",
    "    for r in range(A_shape - 2):\n",
    "        word = int2word[r]\n",
    "        A[r] /= (word_freq[word] + A_shape)\n",
    "        \n",
    "    # convert to log probabilities\n",
    "    pi = np.log(pi)\n",
    "    A = np.log(A)\n",
    "\n",
    "    return pi, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out X_train_int for frost v poe? to build separate MMs?\n",
    "\n",
    "poe_train_data = []\n",
    "frost_train_data = []\n",
    "\n",
    "for idx, line in enumerate(X_train_int):\n",
    "    if y_train[idx] == 'poe':\n",
    "        poe_train_data.append(line)\n",
    "    elif y_train[idx] == 'frost':\n",
    "        frost_train_data.append(line)\n",
    "    else:\n",
    "        print('wtf')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2639, 2639) (2639, 2639)\n"
     ]
    }
   ],
   "source": [
    "poe_pi, poe_A = build_markov_model(poe_train_data)\n",
    "frost_pi, frost_A = build_markov_model(frost_train_data)\n",
    "\n",
    "print(poe_A.shape, frost_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_from_mm(line, pi, A):\n",
    "    '''take line of ints from X_test_ints plus the markov model A/pi matrices\n",
    "    return a probability'''\n",
    "\n",
    "    prob_sum = 0\n",
    "    \n",
    "    for idx in range(len(line) - 1):\n",
    "        curr_word = line[idx]\n",
    "        next_word = line[idx + 1]\n",
    "        if idx == 0:\n",
    "            prob_sum += pi[curr_word]\n",
    "        else:\n",
    "            prob_sum += A[curr_word, next_word]\n",
    "    \n",
    "    return prob_sum[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priors(y_train, author):\n",
    "    auth_count = sum(y == author for y in y_train)\n",
    "    return np.log(auth_count / len(y_train))\n",
    "\n",
    "def calc_accuracy_with_priors(X_data, labels, poe_prior, frost_prior):\n",
    "    num_correct = 0.\n",
    "    for idx, line in enumerate(X_data):\n",
    "        if len(line) > 1:\n",
    "            poe_prob = prob_from_mm(line, poe_pi, poe_A)\n",
    "            frost_prob = prob_from_mm(line, frost_pi, frost_A)\n",
    "\n",
    "            guess = 'poe' if poe_prob > frost_prob else 'frost'\n",
    "            answer = labels[idx]\n",
    "\n",
    "            if guess == answer:\n",
    "                num_correct += 1.\n",
    "    \n",
    "    return num_correct / float(len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912942542077772\n",
      "0.8167053364269141\n"
     ]
    }
   ],
   "source": [
    "poe_prior = get_priors(y_train, 'poe')\n",
    "frost_prior = get_priors(y_train, 'frost')\n",
    "\n",
    "print(calc_accuracy_with_priors(X_train_int, y_train, poe_prior, frost_prior))\n",
    "print(calc_accuracy_with_priors(X_test_int, y_test, poe_prior, frost_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(X_data, labels):\n",
    "    # matrix shape:\n",
    "    ###         guessP  guessF\n",
    "    # actualP   [    ]  [    ]\n",
    "    # actualF   [    ]  [    ]\n",
    "\n",
    "    cm = np.zeros((2,2))\n",
    "\n",
    "    for idx, line in enumerate(X_data):\n",
    "        # prevent case where it's only one word in the line.\n",
    "        if len(line) > 1:\n",
    "            answer = 0 if labels[idx] == 'poe' else 1\n",
    "            poe_prob = prob_from_mm(line, poe_pi, poe_A) + poe_prior\n",
    "            frost_prob = prob_from_mm(line, frost_pi, frost_A) + frost_prior\n",
    "            guess = 0 if poe_prob > frost_prob else 1\n",
    "            \n",
    "            cm[answer, guess] += 1\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 566.   21.]\n",
      " [   0. 1129.]]\n",
      "[[ 69.  61.]\n",
      " [  5. 296.]]\n"
     ]
    }
   ],
   "source": [
    "cm_train = get_confusion_matrix(X_train_int, y_train)\n",
    "cm_test = get_confusion_matrix(X_test_int, y_test)\n",
    "\n",
    "print(cm_train)\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for train: 0.9907854322071084\n",
      "F1 score for test: 0.8996960486322189\n"
     ]
    }
   ],
   "source": [
    "def f1_score_from_cm(cm):\n",
    "    precision = cm[1,1] / (cm[1,1] + cm[0,1])\n",
    "    recall = cm[1,1] / (cm[1,1] + cm[1,0])\n",
    "\n",
    "    return 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "print(f'F1 score for train: {f1_score_from_cm(cm_train)}')\n",
    "print(f'F1 score for test: {f1_score_from_cm(cm_test)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4923b0cf400c235129cc738c3508a6cd52776416c1524016eb17621a3e6dbb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
