{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../large_files/train.csv', delimiter=',', skiprows=1, dtype=int)\n",
    "\n",
    "def set_up_data(d):\n",
    "    # shuffle the data\n",
    "    np.random.shuffle(d)\n",
    "\n",
    "    # split into X and Y (labels are first column)\n",
    "    X = d[:, 1:]\n",
    "    Y = d[:, 0]\n",
    "\n",
    "    # split into train/test\n",
    "    r, c = np.shape(d)\n",
    "    r_90 = r // 90\n",
    "    X_train, X_test = X[:-r_90], X[-r_90:]\n",
    "    Y_train, Y_test = Y[:-r_90], Y[-r_90:]\n",
    "\n",
    "    # normalize.\n",
    "    # takes mean/std for each col (??)\n",
    "    mu = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    \n",
    "    # for all-black images (std == 0), change std to 1 to prevent /0 errors\n",
    "    idx = np.where(std == 0)[0]\n",
    "    assert(np.all(std[idx]) == 0)\n",
    "\n",
    "    np.place(std, std == 0, 1)\n",
    "\n",
    "    X_train = (X_train - mu) / std\n",
    "    X_test = (X_test - mu) / std\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def onehot_encode(y):\n",
    "    N = len(y)\n",
    "    min_y, max_y = np.min(y), np.max(y)\n",
    "    K = (max_y - min_y) + 1\n",
    "\n",
    "    encoded_y = np.zeros((N, K))\n",
    "\n",
    "    for i in range(N):\n",
    "        col_val = y[i]\n",
    "        encoded_y[i, col_val] = 1\n",
    "    \n",
    "    return encoded_y\n",
    "\n",
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1298/1298 [==============================] - 9s 6ms/step - loss: 2.3130 - accuracy: 0.8554\n",
      "Epoch 2/5\n",
      "1298/1298 [==============================] - 8s 6ms/step - loss: 0.5810 - accuracy: 0.9151\n",
      "Epoch 3/5\n",
      "1298/1298 [==============================] - 8s 6ms/step - loss: 0.5618 - accuracy: 0.9173\n",
      "Epoch 4/5\n",
      "1298/1298 [==============================] - 8s 6ms/step - loss: 0.5213 - accuracy: 0.9253\n",
      "Epoch 5/5\n",
      "1298/1298 [==============================] - 8s 6ms/step - loss: 0.5082 - accuracy: 0.9275\n",
      "15/15 - 0s - loss: 0.4866 - accuracy: 0.9270\n",
      "[6 2 5 0 3]\n",
      "[6 2 5 0 3]\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    # step 1: get the data and define all the usual variables\n",
    "    Xtrain, Xtest, Ytrain, Ytest = set_up_data(data)\n",
    "\n",
    "    max_iter = 15\n",
    "    print_period = 50\n",
    "\n",
    "    lr = 0.001\n",
    "    reg = 0.01\n",
    "\n",
    "    N, D = Xtrain.shape\n",
    "    batch_sz = 500\n",
    "    n_batches = N // batch_sz\n",
    "\n",
    "    # define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(300, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(reg)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(reg)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(Xtrain, Ytrain, epochs=5)\n",
    "\n",
    "    model.evaluate(Xtest,  Ytest, verbose=2)\n",
    "\n",
    "    print(tf.argmax(model(Xtest[:5]),1).numpy())\n",
    "    print(Ytest[:5])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 5.2860 - accuracy: 0.7056\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.2755 - accuracy: 0.9248\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.5999 - accuracy: 0.9374\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.4505 - accuracy: 0.9425\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.4106 - accuracy: 0.9419\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.3885 - accuracy: 0.9466\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.3781 - accuracy: 0.9470\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.3782 - accuracy: 0.9476\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.3709 - accuracy: 0.9473\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.3478 - accuracy: 0.9526\n",
      "15/15 - 0s - loss: 0.3498 - accuracy: 0.9485\n",
      "[3 3 8 1 9]\n",
      "[3 3 8 1 9]\n"
     ]
    }
   ],
   "source": [
    "def train_2():\n",
    "    # step 1: get the data and define all the usual variables\n",
    "    Xtrain, Xtest, Ytrain, Ytest = set_up_data(data)\n",
    "\n",
    "    max_iter = 15\n",
    "    print_period = 50\n",
    "\n",
    "    lr = 0.001\n",
    "    reg = 0.01\n",
    "\n",
    "    N, D = Xtrain.shape\n",
    "    batch_sz = 500\n",
    "    n_batches = N // batch_sz\n",
    "\n",
    "    # define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(300, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(reg)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(reg)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(Xtrain, Ytrain, epochs=10, batch_size = batch_sz)\n",
    "\n",
    "    model.evaluate(Xtest,  Ytest, verbose=2)\n",
    "\n",
    "    print(tf.argmax(model(Xtest[:5]),1).numpy())\n",
    "    print(Ytest[:5])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model_2 = train_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b926aed36c516f3967f51fec90ed511fe8a5d480c43eafa224d22d8e046f2ed3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
